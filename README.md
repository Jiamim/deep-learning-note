# deep learning note

### [李宏毅教授深度学习](http://speech.ee.ntu.edu.tw/~tlkagk/courses_MLSD15_2.html '课程地址')

#### [Backpropagation](http://speech.ee.ntu.edu.tw/~tlkagk/courses/MLDS_2015_2/Lecture/DNN%20backprop.ecm.mp4/index.html '反向传播')

#### [Tips for Training Deep Neural Network](http://speech.ee.ntu.edu.tw/~tlkagk/courses/MLDS_2015_2/Lecture/Deep%20More%20(v2).ecm.mp4/index.html '训练神经网络的提示')

#### [Neural Network with Memory](http://speech.ee.ntu.edu.tw/~tlkagk/courses/MLDS_2015_2/Lecture/RNN%20(v4).ecm.mp4/index.html '记忆神经网络')

#### [Training Recurrent Neural Network](http://speech.ee.ntu.edu.tw/~tlkagk/courses/MLDS_2015_2/Lecture/RNN%20training%20(v6).ecm.mp4/index.html '训练循环神经网络')

#### [Introduction of Structured Learning](http://speech.ee.ntu.edu.tw/~tlkagk/courses/MLDS_2015_2/Lecture/Structured%20Introduction%20(v2).ecm.mp4/index.html '结构化学习介绍')

#### Parameter Initialization:
结合了[《解析卷积神经网络—深度学习实践手册》](http://lamda.nju.edu.cn/weixs/book/CNN_book.html '解析卷积神经网络—深度学习实践手册')，感谢作者魏秀参（Xiu-Shen WEI）

#### word2vec: 
参考论文Xin Rong的word2vec Parameter Learning Explained，以及李沐老师的[深度学习课程](http://zh.gluon.ai/chapter_natural-language-processing/index.html '李沐深度学习课程')

#### sigmoid_network，使用转换函数为sigmoid，[参考代码地址](https://github.com/mnielsen/neural-networks-and-deep-learning)

#### CNN For NLP
[Understanding Convolutional Neural Networks for NLP（译文）](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/ '原文地址')<br />
[Implementing a CNN for Text Classification in TensorFlow（译文）](http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/ '原文地址')

#### Weight Initialization
译成中文，原代码地址：https://github.com/udacity/deep-learning/tree/master/weight-initialization 
